{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Ciphar10_Keras_nov_14_2018.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ucfilho/Codigos_Teste/blob/master/Teste_Ciphar10_Keras_nov_14_2018.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "sFK1vE8MS4MM",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#https://www.learnopencv.com/image-classification-using-convolutional-neural-networks-in-keras/\n",
        "# https://keras.io/datasets/\n",
        "#https://www.scipy-lectures.org/advanced/scikit-learn/#putting-it-all-together-face-recognition\n",
        "# https://www.pyimagesearch.com/2017/12/11/image-classification-with-keras-and-deep-learning/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1IQizl8eYh36",
        "colab_type": "code",
        "outputId": "97778b30-d6f8-465e-9dc2-bc3639e6d862",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "cell_type": "code",
      "source": [
        "#from keras.datasets import mnist\n",
        "#(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
        "\n",
        "from keras.datasets import cifar10\n",
        "\n",
        "(train_images, train_labels), (test_images, test_labels) = cifar10.load_data()\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170500096/170498071 [==============================] - 29s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "aNwPqr7SXOGN",
        "colab_type": "code",
        "outputId": "fd809be4-0630-476c-e141-b228ad771c68",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 274
        }
      },
      "cell_type": "code",
      "source": [
        "!pip install keras-tqdm\n",
        "import keras\n",
        "import tensorflow as tf\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras_tqdm import TQDMNotebookCallback\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Dropout\n",
        "from keras.layers import Flatten\n",
        "from keras.constraints import maxnorm\n",
        "from keras.optimizers import SGD\n",
        "from keras.layers.convolutional import Conv2D\n",
        "from keras.layers.convolutional import MaxPooling2D\n",
        "from keras.utils import np_utils\n",
        "from keras.callbacks import Callback\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from keras.preprocessing.image import img_to_array, load_img\n",
        "from keras import layers, models, optimizers\n",
        "from keras import backend as K\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import itertools\n",
        "\n",
        "import matplotlib.image as mpimg\n",
        "import seaborn as sns"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting keras-tqdm\n",
            "  Downloading https://files.pythonhosted.org/packages/16/5c/ac63c65b79a895b8994474de2ad4d5b66ac0796b8903d60cfea3f8308d5c/keras_tqdm-2.0.1-py2.py3-none-any.whl\n",
            "Requirement already satisfied: Keras in /usr/local/lib/python3.6/dist-packages (from keras-tqdm) (2.2.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from keras-tqdm) (4.28.1)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from Keras->keras-tqdm) (1.0.6)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from Keras->keras-tqdm) (1.1.0)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from Keras->keras-tqdm) (1.14.6)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from Keras->keras-tqdm) (2.8.0)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from Keras->keras-tqdm) (1.11.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from Keras->keras-tqdm) (3.13)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from Keras->keras-tqdm) (1.0.5)\n",
            "Installing collected packages: keras-tqdm\n",
            "Successfully installed keras-tqdm-2.0.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "v9Sd70ftLD4A",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        " \n",
        "def createModel():\n",
        "\n",
        "    model = keras.models.Sequential()\n",
        "    model.add(layers.Conv2D(32, (3, 3), input_shape=(32, 32, 3)))\n",
        "    model.add(layers.Activation('relu'))\n",
        "    model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
        "    model.add(layers.Conv2D(32, (3, 3)))\n",
        "    model.add(layers.Activation('relu'))\n",
        "    model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
        "    \n",
        "    model.add(layers.Conv2D(64, (3, 3)))\n",
        "    model.add(layers.Activation('relu'))\n",
        "    model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
        "    model.add(layers.Flatten())\n",
        "    model.add(layers.Dense(64))\n",
        "    model.add(layers.Activation('relu'))\n",
        "    model.add(layers.Dropout(0.5))\n",
        "    model.add(layers.Dense(10))\n",
        "    model.add(layers.Activation('softmax'))\n",
        "\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qEGAQW_7S2N6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "NgtxV0BZLFsn",
        "colab_type": "code",
        "outputId": "9be40163-b37b-437c-9e71-5aea5e93f282",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 645
        }
      },
      "cell_type": "code",
      "source": [
        "model1 = createModel()\n",
        "batch_size = 30\n",
        "epochs = 100\n",
        "model1.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        " \n",
        "history = model1.fit(train_images, train_labels, batch_size=batch_size, epochs=epochs, verbose=1, \n",
        "                   validation_data=(test_images, test_labels))\n",
        " \n",
        " \n",
        "model1.evaluate(test_images, test_labels)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-8e76dff52cb1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m history = model1.fit(train_images, train_labels, batch_size=batch_size, epochs=epochs, verbose=1, \n\u001b[0;32m----> 7\u001b[0;31m                    validation_data=(test_images, test_labels))\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m    950\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    951\u001b[0m             \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 952\u001b[0;31m             batch_size=batch_size)\n\u001b[0m\u001b[1;32m    953\u001b[0m         \u001b[0;31m# Prepare validation data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    954\u001b[0m         \u001b[0mdo_validation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[1;32m    787\u001b[0m                 \u001b[0mfeed_output_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    788\u001b[0m                 \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Don't enforce the batch size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 789\u001b[0;31m                 exception_prefix='target')\n\u001b[0m\u001b[1;32m    790\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    791\u001b[0m             \u001b[0;31m# Generate sample-wise weight values given the `sample_weight` and\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    136\u001b[0m                             \u001b[0;34m': expected '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' to have shape '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m                             \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' but got array with shape '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 138\u001b[0;31m                             str(data_shape))\n\u001b[0m\u001b[1;32m    139\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Error when checking target: expected activation_5 to have shape (10,) but got array with shape (1,)"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "pV2K2dquLRy0",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Loss Curves\n",
        "plt.figure(figsize=[8,6])\n",
        "plt.plot(history.history['loss'],'r',linewidth=3.0)\n",
        "plt.plot(history.history['val_loss'],'b',linewidth=3.0)\n",
        "plt.legend(['Training loss', 'Validation Loss'],fontsize=18)\n",
        "plt.xlabel('Epochs ',fontsize=16)\n",
        "plt.ylabel('Loss',fontsize=16)\n",
        "plt.title('Loss Curves',fontsize=16)\n",
        " \n",
        "# Accuracy Curves\n",
        "plt.figure(figsize=[8,6])\n",
        "plt.plot(history.history['acc'],'r',linewidth=3.0)\n",
        "plt.plot(history.history['val_acc'],'b',linewidth=3.0)\n",
        "plt.legend(['Training Accuracy', 'Validation Accuracy'],fontsize=18)\n",
        "plt.xlabel('Epochs ',fontsize=16)\n",
        "plt.ylabel('Accuracy',fontsize=16)\n",
        "plt.title('Accuracy Curves',fontsize=16)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0yWwFyakLSws",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator\n",
        " \n",
        "ImageDataGenerator(\n",
        "    rotation_range=10.,\n",
        "    width_shift_range=0.1,\n",
        "    height_shift_range=0.1,\n",
        "    shear_range=0.,\n",
        "    zoom_range=.1.,\n",
        "    horizontal_flip=True,\n",
        "    vertical_flip=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "fa4hj4kmLdy_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator\n",
        " \n",
        "model2 = createModel()\n",
        " \n",
        "model2.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        " \n",
        "batch_size = 256\n",
        "epochs = 100\n",
        "datagen = ImageDataGenerator(\n",
        "#         zoom_range=0.2, # randomly zoom into images\n",
        "#         rotation_range=10,  # randomly rotate images in the range (degrees, 0 to 180)\n",
        "        width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n",
        "        height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n",
        "        horizontal_flip=True,  # randomly flip images\n",
        "        vertical_flip=False)  # randomly flip images\n",
        " \n",
        "# Fit the model on the batches generated by datagen.flow().\n",
        "history2 = model2.fit_generator(datagen.flow(train_data, train_labels_one_hot, batch_size=batch_size),\n",
        "                              steps_per_epoch=int(np.ceil(train_data.shape[0] / float(batch_size))),\n",
        "                              epochs=epochs,\n",
        "                              validation_data=(test_data, test_labels_one_hot),\n",
        "                              workers=4)\n",
        " \n",
        "model2.evaluate(test_data, test_labels_one_hot)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "f8jVlvO8LfCO",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Loss Curves\n",
        "plt.figure(figsize=[8,6])\n",
        "plt.plot(history2.history['loss'],'r',linewidth=3.0)\n",
        "plt.plot(history2.history['val_loss'],'b',linewidth=3.0)\n",
        "plt.legend(['Training loss', 'Validation Loss'],fontsize=18)\n",
        "plt.xlabel('Epochs ',fontsize=16)\n",
        "plt.ylabel('Loss',fontsize=16)\n",
        "plt.title('Loss Curves',fontsize=16)\n",
        " \n",
        "# Accuracy Curves\n",
        "plt.figure(figsize=[8,6])\n",
        "plt.plot(history2.history['acc'],'r',linewidth=3.0)\n",
        "plt.plot(history2.history['val_acc'],'b',linewidth=3.0)\n",
        "plt.legend(['Training Accuracy', 'Validation Accuracy'],fontsize=18)\n",
        "plt.xlabel('Epochs ',fontsize=16)\n",
        "plt.ylabel('Accuracy',fontsize=16)\n",
        "plt.title('Accuracy Curves',fontsize=16)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1ATCP3KALn0o",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}